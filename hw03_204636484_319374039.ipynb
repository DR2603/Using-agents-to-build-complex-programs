{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UJSVOB9jeP2P"
      },
      "source": [
        "Doron Rabinian, ID 204636484<BR>\n",
        "Natalia Meergus, ID 319374039"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f52LXPcpeP2Q",
        "jupyter": {
          "is_executing": true
        }
      },
      "source": [
        "!pip install --upgrade --quiet langchain-core langchain-openai\n",
        "!pip install --quiet duckduckgo_search"
      ],
      "outputs": [],
      "execution_count": 1
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "14Hg-qpReP2R"
      },
      "outputs": [],
      "source": [
        "import contextlib\n",
        "import os\n",
        "import json\n",
        "from typing import List, Any, Dict\n",
        "import io\n",
        "\n",
        "from langchain_core.tools import tool, BaseTool\n",
        "from langchain_core.messages import AIMessage, HumanMessage\n",
        "from langchain_openai import AzureChatOpenAI\n",
        "from duckduckgo_search import DDGS\n",
        "from langchain_core.runnables import Runnable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ybGzt-LMeP2R"
      },
      "outputs": [],
      "source": [
        "AZURE_OPENAI_API_KEY = 'e865ffe4387f416ea57d7394ee09fb2e'\n",
        "AZURE_OPENAI_ENDPOINT = 'https://openaifor3267.openai.azure.com/'\n",
        "AZURE_OPENAI_API_VERSION = '2024-02-01'\n",
        "AZURE_OPENAI_DEPLOYMENT = 'gpt4'"
      ]
    },
    {
      "metadata": {
        "id": "dbEY93ELVaZS"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 4,
      "source": [
        "os.environ['AZURE_OPENAI_API_KEY'] = AZURE_OPENAI_API_KEY\n",
        "os.environ['AZURE_OPENAI_ENDPOINT'] = AZURE_OPENAI_ENDPOINT\n",
        "\n",
        "llm = AzureChatOpenAI(\n",
        "    azure_deployment=AZURE_OPENAI_DEPLOYMENT,\n",
        "    api_version=AZURE_OPENAI_API_VERSION,\n",
        "    temperature=0,\n",
        "    max_tokens=None,\n",
        "    timeout=None,\n",
        "    max_retries=2\n",
        ")"
      ]
    },
    {
      "metadata": {
        "id": "M8T3Dc1QVaZS"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 5,
      "source": [
        "@tool\n",
        "def extract_entities_from_file(file_name: str, entity_type: str) -> str:\n",
        "    \"\"\"\n",
        "  The function is given a text file and an “entity type” (could be\n",
        "  “student”, “hobby”, “city” or any type of entity). It returns a\n",
        "  string representing a list of entities of that type in the file\n",
        "  (e.g., “[‘Haifa’, ‘Tel Aviv’]”).\n",
        "  \"\"\"\n",
        "    try:\n",
        "        with open(file_name, 'r') as file:\n",
        "            file_content = file.read()\n",
        "    except FileNotFoundError:\n",
        "        return f\"Error: File {file_name} not found.\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "    if not file_content.strip():\n",
        "        return json.dumps([])  # Return an empty JSON array if the file is empty\n",
        "\n",
        "    prompt = (f'Extract list of all \"{entity_type}\" entities appearing in the following text, in the order of their '\n",
        "              f'appearance:\\n'\n",
        "              f'\"{file_content}\"')\n",
        "    response = llm.invoke([HumanMessage(prompt)])\n",
        "    try:\n",
        "        return str(response.content)\n",
        "    except Exception as e:\n",
        "        return f\"Error: Unable to format response content. {str(e)}\""
      ]
    },
    {
      "metadata": {
        "id": "9zoBBxUSVaZT"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 6,
      "source": [
        "@tool\n",
        "def internet_search_attribute(a_entity_type: str, a_entity: str, a_attribute: str) -> str:\n",
        "    \"\"\"\n",
        "  The function is given an entity type (e.g. 'city'), an entity (e.g, ‘Tel Aviv’)\n",
        "  and an attribute (e.g.,’current population’).\n",
        "  It searches the Internet to find the attribute of the entity.\n",
        "  It then asks the LLM to review the search results and\n",
        "  returns a JSON structure of the form\n",
        "  {\"a_entity\": {a_entity}, \"{attribute}\": Answer}.\n",
        "  Example answer: { \"city\": ”Tel Aviv\", \"population\": 4,400,000 }\n",
        "  \"\"\"\n",
        "    query = f'What is {a_attribute} of {a_entity}?'\n",
        "    search_results = DDGS().text(query, max_results=2)\n",
        "    prompt = f'Read {len(search_results)} text(s) below and comprehend what is ' \\\n",
        "             f'{a_attribute} of {a_entity} {a_entity_type}.\\n' \\\n",
        "             f'Reply should be only JSON structure in the form: ' \\\n",
        "             f'{{ \"{a_entity_type}\": \"{a_entity}\", \"{a_attribute}\": <value you have found> }}.\\n'\n",
        "    prompt += '\\n'.join([f'Text {i + 1}: \"{result}\".' for i, result in enumerate(search_results)])\n",
        "    response = llm.invoke([HumanMessage(prompt)])\n",
        "    try:\n",
        "        return str(response.content)\n",
        "    except Exception as e:\n",
        "        return f\"Error: Unable to format response content. {str(e)}\""
      ]
    },
    {
      "metadata": {
        "id": "gJCY64MRVaZT"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 7,
      "source": [
        "@tool\n",
        "def generate_analysis_program(analysis_request: str,\n",
        "                              input_file: str,\n",
        "                              columns: str,\n",
        "                              row_example: str,\n",
        "                              output_file: str) -> str:\n",
        "    \"\"\"\n",
        "  This tool takes an analysis request, a csv input_file, the first\n",
        "  line of the file containing the column names, another line of the file\n",
        "  with example data, and an output_file. The analysis_request\n",
        "  describes analysis of the csv input_file to be performed. This\n",
        "  tool generates a Python program to perform the analysis. The\n",
        "  program writes the output, a JSON object, to the output_file.\n",
        "  generate_analysis_program tool returns the generated Python code.\n",
        "  \"\"\"\n",
        "    prompt = 'Generate a correct and executable Python code block. ' \\\n",
        "             'Respond with code only, without any extra text or explanations.\\n' \\\n",
        "             f'The code snippet must read the CSV file \"{input_file}\", ' \\\n",
        "             f'with the header (columns) as \"{columns}\", ' \\\n",
        "             f'and example row as: \"{row_example}\".\\n' \\\n",
        "             f'The code should perform the following analysis: \"{analysis_request}\".\\n' \\\n",
        "             f'It must then save the analysis result in JSON format to a file named \"{output_file}\".\\n' \\\n",
        "             'Ensure to import the necessary libraries: import pandas as pd, import json.'\n",
        "    response = llm.invoke([HumanMessage(prompt)])\n",
        "    python_code = str(response.content)\n",
        "    # Drop python code wrapping ```python <code> ```\n",
        "    python_code_block_open = '```python\\n'\n",
        "    python_code_block_close = '\\n```'\n",
        "    if python_code.startswith(python_code_block_open):\n",
        "        python_code = python_code[len(python_code_block_open):]\n",
        "    if python_code.endswith(python_code_block_close):\n",
        "        python_code = python_code[:-len(python_code_block_close)]\n",
        "\n",
        "    return python_code.strip()"
      ]
    },
    {
      "metadata": {
        "id": "oLfFYTjQVaZU"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 8,
      "source": [
        "@tool\n",
        "def execute_python_program(program_fn: str, output_fn: str) -> str:\n",
        "    \"\"\"\n",
        "    This tool executes a Python program from a given file.\n",
        "    It captures the output and any exceptions that occur during execution.\n",
        "    Returns the output or error message as a string.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        with open(program_fn, 'r') as file:\n",
        "            code = file.read()\n",
        "\n",
        "        output = io.StringIO()\n",
        "        error_output = io.StringIO()\n",
        "\n",
        "        with contextlib.redirect_stdout(output), contextlib.redirect_stderr(error_output):\n",
        "            try:\n",
        "                exec(code, {})\n",
        "            except Exception as e:\n",
        "                error_message = f\"Error: {str(e)}\\n{error_output.getvalue()}\"\n",
        "                with open(output_fn, 'w') as output_file:\n",
        "                    output_file.write(error_message)\n",
        "                return f\"Program did not execute successfully. Error: {str(e)}\"\n",
        "\n",
        "            return \"Program executed successfully and output is written to the file.\"\n",
        "\n",
        "\n",
        "    except FileNotFoundError:\n",
        "        error_message = f\"Error: File {program_fn} not found.\"\n",
        "        with open(output_fn, 'w') as output_file:\n",
        "            output_file.write(error_message)\n",
        "        return error_message\n",
        "\n",
        "    except Exception as e:\n",
        "        error_message = f\"Error: {str(e)}\"\n",
        "        with open(output_fn, 'w') as output_file:\n",
        "            output_file.write(error_message)\n",
        "        return error_message"
      ]
    },
    {
      "metadata": {
        "id": "1ytquUwfVaZU"
      },
      "cell_type": "code",
      "outputs": [],
      "execution_count": 9,
      "source": [
        "@tool\n",
        "def write_file(file_content: str, fn: str) -> str:\n",
        "    \"\"\"\n",
        "    This tool writes the given content to a specified file.\n",
        "    Returns a success message or an error message.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        print(\"Writing to file with parameters:\", file_content)\n",
        "        with open(fn, 'w') as file:\n",
        "            file.write(file_content)\n",
        "        return f\"Success: Content written to {fn}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "opB5uyseeP2S"
      },
      "outputs": [],
      "source": [
        "class Agent:\n",
        "    def __init__(self, agent: AzureChatOpenAI, tools: List[BaseTool]):\n",
        "        self.llm_with_tools = agent.bind_tools(tools)\n",
        "        self.tools = tools\n",
        "        self.tool_map = {tool.name: tool for tool in tools}\n",
        "        self.chain = self.llm_with_tools | self.call_tools\n",
        "        self.messages: List[AIMessage] = []\n",
        "        self.log_file = None\n",
        "        self.llm_invocations = 0\n",
        "        self.function_calls = 0\n",
        "\n",
        "    def _log(self, message: str):\n",
        "        print(message)\n",
        "        if self.log_file:\n",
        "            with open(self.log_file, 'a') as log:\n",
        "                log.write(message + '\\n')\n",
        "\n",
        "    def _log_parameters(self, parameters: Dict[str, Any]):\n",
        "        for name, value in parameters.items():\n",
        "            if isinstance(value, str) and len(value) > 50:\n",
        "                value = value[:50] + '...'\n",
        "            self._log(f'Parameter {name} = {value}')\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_query(input: Dict[str, Any]) -> str:\n",
        "        query_file_name = input['query_name']\n",
        "        with open(query_file_name) as query_file:\n",
        "            return query_file.read()\n",
        "\n",
        "    @staticmethod\n",
        "    def _get_files_description(inputfile: Dict[str, Any]) -> List[str]:\n",
        "        return ['{0}) \"{1}\" file: {2}'.format(n_file + 1, file_resource['file_name'], file_resource['description'])\n",
        "                for n_file, file_resource in enumerate(inputfile['file_resources'])]\n",
        "\n",
        "    def loop(self, input_json: str) -> str:\n",
        "        try:\n",
        "            with open(input_json) as json_file:\n",
        "                inputfile = json.load(json_file)\n",
        "            self.log_file = f'log_{inputfile[\"query_name\"].replace(\".txt\", \"\")}.txt'\n",
        "            query = self._get_query(inputfile)\n",
        "            files_descriptions = self._get_files_description(inputfile)\n",
        "\n",
        "            prompt = f'You are given {len(files_descriptions)} files:\\n'\n",
        "            prompt += '\\n'.join(files_descriptions) + f'\\nYour mission: {query}'\n",
        "            self.messages = [HumanMessage(prompt)]\n",
        "\n",
        "            self._log(f\"**Entering loop**\")\n",
        "            self._log(f\"Initial prompt: {prompt}\")\n",
        "\n",
        "            while self.llm_invocations < 10 and self.function_calls < 10:\n",
        "                self.llm_invocations += 1\n",
        "                response = self.llm_with_tools.invoke(self.messages)\n",
        "                if not response.tool_calls:\n",
        "                    self._log(f\"**Leaving loop**\")\n",
        "                    return response.content\n",
        "                self.messages.append(response)\n",
        "                self.call_tools(response)\n",
        "            self._log(f\"**Leaving loop**\")\n",
        "        except Exception as e:\n",
        "            self._log(f\"Error during loop execution: {e}\")\n",
        "            return f\"Error: {str(e)}\"\n",
        "\n",
        "    def call_tools(self, msg: AIMessage) -> Runnable:\n",
        "        \"\"\"Simple sequential tool calling helper.\"\"\"\n",
        "        tool_calls = msg.tool_calls.copy()\n",
        "        for tool_call in tool_calls:\n",
        "            if self.function_calls >= 10:\n",
        "                break\n",
        "            try:\n",
        "                self.function_calls += 1\n",
        "                self._log(f'** Entering Agent {tool_call[\"name\"]} **')\n",
        "                self._log_parameters(tool_call[\"args\"])\n",
        "                self._log(f\"Calling tool {tool_call['name']} with args: {tool_call['args']}\")\n",
        "\n",
        "                output = self.tool_map[tool_call[\"name\"]].invoke(tool_call[\"args\"])\n",
        "                self._log(f'Result from tool {tool_call[\"name\"]}: {output}')\n",
        "\n",
        "                self._log(f'** Leaving Agent {tool_call[\"name\"]} **')\n",
        "                if tool_call[\"name\"] == \"generate_analysis_program\":\n",
        "                    tool_call['args']['file_content'] = output\n",
        "                else:\n",
        "                    tool_call['output'] = output\n",
        "\n",
        "                self.messages.append({'role': 'tool',\n",
        "                                      'content': f'Requesting {tool_call[\"name\"]}',\n",
        "                                      'tool_call_id': tool_call[\"id\"]})\n",
        "            except Exception as e:\n",
        "                self._log(f\"Error invoking tool {tool_call['name']}: {e}\")\n",
        "                error_output = f\"Error: {str(e)}\"\n",
        "                tool_call['output'] = error_output\n",
        "                self.messages.append({'role': 'tool',\n",
        "                                      'content': f'Error invoking {tool_call[\"name\"]}',\n",
        "                                      'tool_call_id': tool_call[\"id\"],\n",
        "                                      'error': str(e)})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "5s4ydOzqeP2T",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "3917d913-87e2-4be5-9462-b30d1129c3ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "**Entering loop**\n",
            "Initial prompt: You are given 2 files:\n",
            "1) \"class2.csv\" file: A csv file describing students and their grades.  the first line contains the columns (field names) of each following row.  They are:  First, Last, Year, Class, Name,Grade. An example row is: Shalom,Levi,3,Calculus,93.5\n",
            "2) \"students.txt\" file: a text file containing information on some of the students, including his or her aspirations, favorite city, and hobbies.\n",
            "Your mission: Generate a Python program that finds the average grade of all the students. The result should be represented as a JSON object with one field, 'average_grade', whose value is a number, and written to the file query3.json. The Python program itself should be stored in the file \"query3.py\".  Before finishing, execute the program stored in the file \"query3.py\".\n",
            "\n",
            "** Entering Agent generate_analysis_program **\n",
            "Parameter analysis_request = find the average grade of all the students\n",
            "Parameter input_file = class2.csv\n",
            "Parameter columns = First,Last,Year,Class,Name,Grade\n",
            "Parameter row_example = Shalom,Levi,3,Calculus,93.5\n",
            "Parameter output_file = query3.json\n",
            "Calling tool generate_analysis_program with args: {'analysis_request': 'find the average grade of all the students', 'input_file': 'class2.csv', 'columns': 'First,Last,Year,Class,Name,Grade', 'row_example': 'Shalom,Levi,3,Calculus,93.5', 'output_file': 'query3.json'}\n",
            "Result from tool generate_analysis_program: import pandas as pd\n",
            "import json\n",
            "\n",
            "# Read the CSV file\n",
            "df = pd.read_csv(\"class2.csv\")\n",
            "\n",
            "# Calculate the average grade\n",
            "average_grade = df['Grade'].mean()\n",
            "\n",
            "# Save the result in JSON format\n",
            "with open(\"query3.json\", \"w\") as outfile:\n",
            "    json.dump({\"Average Grade\": average_grade}, outfile)\n",
            "** Leaving Agent generate_analysis_program **\n",
            "** Entering Agent write_file **\n",
            "Parameter file_content = import pandas as pd\n",
            "import json\n",
            "\n",
            "# Read the CSV fi...\n",
            "Parameter fn = query3.py\n",
            "Calling tool write_file with args: {'file_content': 'import pandas as pd\\nimport json\\n\\n# Read the CSV file\\ndf = pd.read_csv(\"class2.csv\")\\n\\n# Calculate the average grade\\naverage_grade = df[\\'Grade\\'].mean()\\n\\n# Save the result in JSON format\\nwith open(\"query3.json\", \"w\") as outfile:\\n    json.dump({\"Average Grade\": average_grade}, outfile)', 'fn': 'query3.py'}\n",
            "Writing to file with parameters: import pandas as pd\n",
            "import json\n",
            "\n",
            "# Read the CSV file\n",
            "df = pd.read_csv(\"class2.csv\")\n",
            "\n",
            "# Calculate the average grade\n",
            "average_grade = df['Grade'].mean()\n",
            "\n",
            "# Save the result in JSON format\n",
            "with open(\"query3.json\", \"w\") as outfile:\n",
            "    json.dump({\"Average Grade\": average_grade}, outfile)\n",
            "Result from tool write_file: Success: Content written to query3.py\n",
            "** Leaving Agent write_file **\n",
            "** Entering Agent execute_python_program **\n",
            "Parameter program_fn = query3.py\n",
            "Parameter output_fn = query3.json\n",
            "Calling tool execute_python_program with args: {'program_fn': 'query3.py', 'output_fn': 'query3.json'}\n",
            "Result from tool execute_python_program: Program executed successfully and output is written to the file.\n",
            "** Leaving Agent execute_python_program **\n",
            "**Leaving loop**\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'The Python program has been successfully executed and the average grade of all the students has been written to the file \"query3.json\".'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "AVAILABLE_TOOLS = [\n",
        "    extract_entities_from_file,\n",
        "    internet_search_attribute,\n",
        "    generate_analysis_program,\n",
        "    execute_python_program,\n",
        "    write_file\n",
        "]\n",
        "agent = Agent(llm, AVAILABLE_TOOLS)\n",
        "agent.loop(\"input.json\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5-J3bWTBdHE8"
      },
      "execution_count": 11,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}